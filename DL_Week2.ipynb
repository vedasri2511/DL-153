{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkS0y8ixsOWc4AMlQ+zdY2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedasri2511/DL-153/blob/main/DL_Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* dl deals with non linear data(curve)\n",
        "* more pixels more acc\n",
        "* automatic feature extraction\n",
        "* interpretation is difficult\n",
        "* uses graphical and tensor processing unit\n",
        "* data, model selection(no model which is perfect depends on parameters)\n",
        "* so selecting model it is noted that which metric is imp for which type of prob like for imbalance f1 score (its harmonic mean of per and recall)\n",
        "* we use keras its easy for quick speed similar to tf, tf for ml and dl for neural network and video kind of data, pytorch for nlp, cntk frameworks\n",
        "* to conclude we use keras\n",
        "* derivation of error is gradient\n",
        "* sequential means feed forward nn\n",
        "* verbose is enabled to see op in each iteration\n",
        "* g is agg and f is activation function\n",
        "* steps of perceptron: it takes input, it sums, it up checks the ip and gives the op\n",
        "* bias acts as a decision boundary and adds non linearity(when all ip becomes 0 then bias helps to make the decision)\n",
        "* fired: op is 1(when bias is increased)\n",
        "* step gives 0 or 1 and sigmoid gives prob value\n",
        "* for ip we use data point as term\n",
        "* dp can be separable for and and or op but not for xor(same same unte 0)(cant be divided using a single line. for and and or 3 are one side and one dp is on another side so they are separable)\n",
        "*\n",
        "\n"
      ],
      "metadata": {
        "id": "0BZxX0U-kjad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement AND and OR logic operations using a single perceptron, and verify the correctness of the output using appropriate truth tables. (linear Data)\n",
        "import numpy as np\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "class perceptron:\n",
        "  def __init__(self,w,b):\n",
        "    self.w=w\n",
        "    self.b=b\n",
        "  def predict(self,inputs):\n",
        "    total=np.dot(self.w,inputs)+self.b\n",
        "    return step(total)\n",
        "w=np.array([1,1])\n",
        "b=-1.5\n",
        "and_op=perceptron(w,b)\n",
        "for x in [(0,0),(0,1),(1,0),(1,1)]:\n",
        "  print(x,\"->\",and_op.predict(np.array(x)))"
      ],
      "metadata": {
        "id": "WmMmrb7xkoF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b33547-b4dc-41b8-c3ee-dd7402f58ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 0) -> 0\n",
            "(0, 1) -> 0\n",
            "(1, 0) -> 0\n",
            "(1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#or\n",
        "import numpy as np\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "class per:\n",
        "  def __init__(self,w,b):\n",
        "    self.w=w\n",
        "    self.b=b\n",
        "  def predict(self,inp):\n",
        "    t=np.dot(self.w,inp)+self.b\n",
        "    return step(t)\n",
        "w=np.array([1,1])\n",
        "b=-0.5\n",
        "or_op=per(w,b)\n",
        "for x in [(0,0),(0,1),(1,0),(1,1)]:\n",
        "  print(x,\"->\",or_op.predict(np.array(x)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqZVuofPpfVj",
        "outputId": "a02f559a-fdc2-4557-8b2a-9b0f13a193fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 0) -> 0\n",
            "(0, 1) -> 1\n",
            "(1, 0) -> 1\n",
            "(1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#xor\n",
        "import numpy as np\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "class per:\n",
        "  def __init__(self,w,b):\n",
        "    self.w=w\n",
        "    self.b=b\n",
        "  def predict(self,inp):\n",
        "    t=np.dot(self.w,inp)+self.b\n",
        "    return step(t)\n",
        "w=np.array([1,1])\n",
        "b=-0.5\n",
        "or_op=per(w,b)\n",
        "for x in [(0,0),(0,1),(1,0),(1,1)]:\n",
        "  print(x,\"->\",or_op.predict(np.array(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMUFCUqmswJb",
        "outputId": "c9b46398-d31a-4da6-9b95-2bde9f016e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 0) -> 0\n",
            "(0, 1) -> 1\n",
            "(1, 0) -> 1\n",
            "(1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#xnor gate\n",
        "def step(x):\n",
        "    if x > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "def not_gate(x):\n",
        "    return 0 if x == 1 else 1\n",
        "def neuron(x1, x2, w1, w2, b):\n",
        "    net = (x1 * w1) + (x2 * w2) + b\n",
        "    return step(net)\n",
        "def xor_gate(A, B):\n",
        "    h1 = neuron(A, B, w1=1, w2=1, b=0)\n",
        "    h2 = neuron(A, B, w1=-1, w2=-1, b=2)\n",
        "    y = neuron(h1, h2, w1=1, w2=1, b=-1)\n",
        "    return y\n",
        "# XNOR = NOT(XOR)\n",
        "def xnor_gate(A, B):\n",
        "    xor_out = xor_gate(A, B)\n",
        "    return not_gate(xor_out)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"A B | XOR XNOR\")\n",
        "    test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "    for A, B in test_inputs:\n",
        "        print(f\"{A} {B} |  {xor_gate(A, B)}    {xnor_gate(A, B)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dBVCEfBxAbZ",
        "outputId": "b443ea5f-4793-4a77-a28f-34ba8526b68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A B | XOR XNOR\n",
            "0 0 |  0    1\n",
            "0 1 |  1    0\n",
            "1 0 |  1    0\n",
            "1 1 |  0    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "X = [\n",
        "    [1, 1, 0, 0.9],   # like\n",
        "    [0, 1, 1, 0.85],  # like\n",
        "    [1, 0, 0, 0.6],   # like\n",
        "    [0, 0, 0, 0.4],   # dislike\n",
        "    [0, 1, 0, 0.45],  # dislike\n",
        "    [1, 0, 1, 0.95]   # like\n",
        "]\n",
        "\n",
        "y = [1, 1, 1, 0, 0, 1]  # labels\n",
        "\n",
        "\n",
        "# Initialize weights and bias\n",
        "weights = [0, 0, 0, 0]\n",
        "bias = 0\n",
        "learning_rate = 0.1\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "# Perceptron training\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "    for i in range(len(X)):\n",
        "        net = sum(X[i][j] * weights[j] for j in range(4)) + bias\n",
        "        prediction = step(net)\n",
        "        error = y[i] - prediction\n",
        "\n",
        "        # Update weights and bias\n",
        "        for j in range(4):\n",
        "            weights[j] += learning_rate * error * X[i][j]\n",
        "        bias += learning_rate * error\n",
        "\n",
        "        print(\"Weights:\", weights, \"Bias:\", bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsScyxa6xzuq",
        "outputId": "c70c70dc-e007-496a-c036-6bbf31392c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Weights: [0.0, 0.0, 0.0, 0.0] Bias: 0.0\n",
            "Weights: [0.0, 0.0, 0.0, 0.0] Bias: 0.0\n",
            "Weights: [0.0, 0.0, 0.0, 0.0] Bias: 0.0\n",
            "Weights: [0.0, 0.0, 0.0, -0.04000000000000001] Bias: -0.1\n",
            "Weights: [0.0, 0.0, 0.0, -0.04000000000000001] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.05499999999999999] Bias: 0.0\n",
            "\n",
            "Epoch 2\n",
            "Weights: [0.1, 0.0, 0.1, 0.05499999999999999] Bias: 0.0\n",
            "Weights: [0.1, 0.0, 0.1, 0.05499999999999999] Bias: 0.0\n",
            "Weights: [0.1, 0.0, 0.1, 0.05499999999999999] Bias: 0.0\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "\n",
            "Epoch 3\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "\n",
            "Epoch 4\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "\n",
            "Epoch 5\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n",
            "Weights: [0.1, 0.0, 0.1, 0.014999999999999986] Bias: -0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of sigmoid\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Movie features: [Matt Damon, Thriller, Nolan, IMDb rating]\n",
        "X = np.array([\n",
        "    [1, 1, 0, 0.85],\n",
        "    [0, 1, 1, 0.90],\n",
        "    [1, 0, 0, 0.60],\n",
        "    [0, 0, 0, 0.40],\n",
        "    [0, 1, 0, 0.45],\n",
        "    [1, 0, 1, 0.95],\n",
        "    [0, 0, 1, 0.50],\n",
        "    [1, 1, 1, 0.92]\n",
        "])\n",
        "\n",
        "# Output labels\n",
        "y = np.array([\n",
        "    [1],\n",
        "    [1],\n",
        "    [1],\n",
        "    [0],\n",
        "    [0],\n",
        "    [1],\n",
        "    [0],\n",
        "    [1]\n",
        "])\n",
        "\n",
        "\n",
        "# ---------------- INITIALIZATION ----------------\n",
        "np.random.seed(42)\n",
        "\n",
        "W1 = np.random.rand(4, 3)    # Input → Hidden (4 features, 3 neurons)\n",
        "b1 = np.random.rand(1, 3)\n",
        "\n",
        "W2 = np.random.rand(3, 1)    # Hidden → Output\n",
        "b2 = np.random.rand(1, 1)\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 5000\n",
        "\n",
        "\n",
        "# ---------------- TRAINING ----------------\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # Forward propagation\n",
        "    hidden_input = np.dot(X, W1) + b1\n",
        "    hidden_output = sigmoid(hidden_input)\n",
        "\n",
        "    final_input = np.dot(hidden_output, W2) + b2\n",
        "    y_pred = sigmoid(final_input)\n",
        "\n",
        "    # Loss (Mean Squared Error)\n",
        "    error = y - y_pred\n",
        "    loss = np.mean(error ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    d_output = error * sigmoid_derivative(y_pred)\n",
        "    d_hidden = d_output.dot(W2.T) * sigmoid_derivative(hidden_output)\n",
        "\n",
        "    # Update weights and biases\n",
        "    W2 += hidden_output.T.dot(d_output) * learning_rate\n",
        "    b2 += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    W1 += X.T.dot(d_hidden) * learning_rate\n",
        "    b1 += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "print(\"\\nMovie Preference Prediction:\")\n",
        "for i in range(len(X)):\n",
        "    decision = \"GO \" if y_pred[i][0] >= 1 else \"NOT GO \"\n",
        "    print(X[i], \"->\", decision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ77Cocn7_kf",
        "outputId": "ab5e4b63-d678-4962-fb3b-18741981d0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2434\n",
            "Epoch 1000, Loss: 0.0136\n",
            "Epoch 2000, Loss: 0.0039\n",
            "Epoch 3000, Loss: 0.0020\n",
            "Epoch 4000, Loss: 0.0013\n",
            "\n",
            "Movie Preference Prediction:\n",
            "[1.   1.   0.   0.85] -> NOT GO \n",
            "[0.  1.  1.  0.9] -> NOT GO \n",
            "[1.  0.  0.  0.6] -> NOT GO \n",
            "[0.  0.  0.  0.4] -> NOT GO \n",
            "[0.   1.   0.   0.45] -> NOT GO \n",
            "[1.   0.   1.   0.95] -> NOT GO \n",
            "[0.  0.  1.  0.5] -> NOT GO \n",
            "[1.   1.   1.   0.92] -> NOT GO \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WEEK3\n"
      ],
      "metadata": {
        "id": "P8VekjkQmfJT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "awDhDHKUmlOp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}